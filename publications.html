<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M. S. B. Siddiqui - Publications</title>
    <!-- CSS Links etc. -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Use the final navigation bar with the dark mode toggle -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">M. S. B. Siddiqui</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link active" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="teaching.html">Teaching</a></li>
                    <li class="nav-item"><a class="nav-link" href="experience.html">Experience</a></li>
                    <li class="nav-item"><a class="nav-link" href="qualifications.html">Credentials</a></li>
                    <li class="nav-item"><a class="nav-link" href="awards.html">Awards</a></li>
                    <li class="nav-item"><a class="nav-link" href="others.html">Others</a></li>
                </ul>
                <button id="theme-toggle" class="btn theme-toggle-btn ms-2">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <section id="publications" class="section fade-in">
            <div class="container">
                <h2 class="mb-5">Publications</h2>

                <!-- Journal Articles Section -->
                <h3 class="mb-4">Journal Articles</h3>
                <div class="publications-list mb-5">
                    <!-- Pub 1: DUA-D2C -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book-open"></i> Journal Article</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2025</span>
                            <span class="pub-status"><span class="pub-status-dot review"></span> Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>DUA-D2C: Dynamic Uncertainty Aware Overfitting Remediation in Deep Learning</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, M. M. Islam, M. G. R. Alam</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at <em>Complex & Intelligent Systems</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal1"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2411.15876" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/DUA-D2C" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- Pub 2: S3F-Net -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book-open"></i> Journal Article</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2025</span>
                            <span class="pub-status"><span class="pub-status-dot review"></span> Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>S³F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, M. I. H. Bhuiyan</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at <em>IEEE Journal of Biomedical and Health Informatics</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal2"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2509.23442" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/S3F-Net" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                     <!-- Pub 3: Mixed-Methods -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book-open"></i> Journal Article</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2025</span>
                            <span class="pub-status"><span class="pub-status-dot review"></span> Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>A Mixed-Methods Analysis of Repression and Mobilization in Bangladesh's July Revolution...</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, A. D. Roy</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at <em>Social Forces</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal3"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2510.06264" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/July-Revolution-Analysis" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Conference Papers Section -->
                <h3 class="mb-4">Conference Papers</h3>
                <div class="publications-list">
                    <!-- Pub 4: AMR-EnsembleNet -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2026</span>
                            <span class="pub-status"><span class="pub-status-dot accepted"></span> Accepted</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>Fusing Sequence Motifs and Pan-Genomic Features: Antimicrobial Resistance Prediction...</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, N. Tarannum</p>
                                <p class="venue"><i class="fas fa-university"></i> To appear in <em>SCA/HPCAsia 2026</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal4"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://www.biorxiv.org/content/early/2025/09/27/2025.09.27.678993" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AMR-EnsembleNet" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                     <!-- Pub 5: AudioFuse -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2026</span>
                            <span class="pub-status"><span class="pub-status-dot review"></span> Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture...</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, U. Saha</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at <em>ICASSP 2026</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal5"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2509.23454" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AudioFuse" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                     <!-- Pub 6: D2C -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2024</span>
                            <span class="pub-status"><span class="pub-status-dot published"></span> Published</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>Divide2Conquer (D2C): A Decentralized Approach Towards Overfitting Remediation...</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, M. M. Islam, M. G. R. Alam</p>
                                <p class="venue"><i class="fas fa-university"></i> 2024 IEEE International Conference on Big Data (BigData)</p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal6"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://doi.org/10.1109/BigData62323.2024.10826082" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/Divide2Conquer" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- Pub 7: FedNet -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2022</span>
                            <span class="pub-status"><span class="pub-status-dot published"></span> Published</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>FedNet: Federated Implementation of Neural Networks for Facial Expression Recognition</h4>
                                <p class="authors"><i class="fas fa-users"></i> <strong>M. S. B. Siddiqui</strong>, S. A. Shusmita, S. Sabreen, M. G. R. Alam</p>
                                <p class="venue"><i class="fas fa-university"></i> 2022 International Conference on Decision Aid Sciences and Applications (DASA)</p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal7"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://doi.org/10.1109/DASA54658.2022.9765165" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/FedNet-Federated-Implementation-of-CNN-for-Facial-Expression-Recognition" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                     <!-- Pub 8: Bioradiolocation -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2022</span>
                            <span class="pub-status"><span class="pub-status-dot published"></span> Published</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>Bioradiolocation-Based Multi-Class Sleep Stage Classification Using Time and Frequency Features...</h4>
                                <p class="authors"><i class="fas fa-users"></i> M. S. I. Siam, <strong>M. S. B. Siddiqui</strong>, M. Abedin, M. I. H. Bhuiyan</p>
                                <p class="venue"><i class="fas fa-university"></i> 2022 12th International Conference on Electrical and Computer Engineering (ICECE)</p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal8"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://doi.org/10.1109/ICECE57408.2022.10089093" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

            </div>
        </section>

        <!-- Connect Section -->
        <section id="connect" class="section fade-in">
             <div class="container">
                <h2>Connect</h2>
                <div class="row">
                    <div class="col-12">
                        <div class="insight-card connect text-center">
                            <h4><i class="fas fa-globe"></i> Get in Touch</h4>
                            <p>Find me on academic and professional networks, or reach out via email.</p>
                            <div class="social-links">
                                <a href="https://github.com/Saiful185" class="btn social-btn github" title="GitHub" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-github"></i> GitHub
                                </a>
                                <a href="https://scholar.google.com/citations?user=kSXa-48AAAAJ&hl=en" class="btn social-btn scholar" title="Google Scholar" target="_blank" rel="noopener noreferrer">
                                    <i class="fas fa-graduation-cap"></i> Google Scholar
                                </a>
                                <a href="https://www.youtube.com/@saifulbariiftu/playlists" class="btn social-btn youtube" title="YouTube" target="_blank" rel="noopener noreferrer">
                                    <i class="fab fa-youtube"></i> YouTube
                                </a>
                            </div>
                            <div class="contact-info mt-4">
                                <p><i class="fas fa-envelope"></i> <a href="mailto:saiful.bari@bracu.ac.bd">saiful.bari@bracu.ac.bd</a></p>
                                <p><i class="fas fa-map-marker-alt"></i>North Badda, Dhaka-1212, Bangladesh</p>
                                <p><i class="fas fa-phone"></i> +880-1758805835</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <!-- =============================================== -->
    <!-- Abstract Modals (Placed at the bottom) -->
    <!-- =============================================== -->
    <!-- Modal 1 -->
    <div class="modal fade" id="abstractModal1" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>This paper introduces Dynamic Uncertainty-Aware Divide to Conquer (DUA-D2C), an advanced framework designed to mitigate overfitting in deep neural networks. Overfitting, a persistent challenge where models perform well on training data but poorly on unseen data, is exacerbated in decentralized and data-heterogeneous environments. DUA-D2C addresses this by integrating aleatoric uncertainty principles into the D2C methodology. This approach enables dynamic sample weighting and adaptive hyperparameter adjustments based on data confidence levels, leading to more robust and generalizable models. Our extensive experiments across various datasets, including CIFAR-10, CIFAR-100, and Tiny ImageNet, demonstrate that DUA-D2C consistently outperforms baseline D2C and centralized training methods in terms of test accuracy and overfitting reduction, particularly in scenarios with significant label noise and class imbalance. The results highlight the framework's potential for enhancing model reliability in real-world, decentralized applications, such as medical imaging and autonomous systems.</p></div></div></div></div>
    <!-- Modal 2 -->
    <div class="modal fade" id="abstractModal2" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>This paper introduces the Spatial-Spectral Summarizer Fusion Network (S³F-Net), a novel multi-modal deep learning architecture for medical image classification. Fusing information from different imaging modalities, such as Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET), offers a promising avenue for improving diagnostic accuracy. However, existing fusion methods often struggle with high-dimensional data and suboptimal feature integration. S³F-Net addresses these challenges by employing a dual-branch Vision Transformer (ViT) architecture with specialized summarizer modules. The spatial summarizer captures contextual relationships within individual modalities, while the spectral summarizer identifies salient cross-modal correlations. By fusing the outputs of these summarizers, S³F-Net creates a rich, discriminative feature representation. We evaluate our model on a multi-modal brain tumor classification dataset, demonstrating that S³F-Net significantly outperforms state-of-the-art fusion techniques in terms of accuracy, robustness, and computational efficiency. Our results highlight the potential of S³F-Net to enhance computer-aided diagnosis and provide more reliable insights for clinical decision-making.</p></div></div></div></div>
    <!-- Modal 3 -->
    <div class="modal fade" id="abstractModal3" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>This study presents a mixed-methods analysis of the July Revolution in Bangladesh, focusing on the interplay between state repression and citizen mobilization. We leverage a unique dataset comprising social media activity, news reports, and eyewitness accounts to construct a comprehensive timeline of events. Our quantitative approach employs machine learning models to classify protest dynamics and statistical modeling to identify the causal impact of repressive tactics on mobilization patterns. We find that while initial repression temporarily suppressed dissent, it ultimately triggered a backlash effect, leading to increased protest participation and coordination. The qualitative analysis, based on thematic coding of narratives, reveals the crucial role of digital platforms in disseminating information, fostering a collective identity, and organizing logistical support. By integrating computational techniques with qualitative insights, our research offers a nuanced understanding of how modern social movements navigate state-led coercion in the digital age. The findings contribute to the broader literature on social movements, authoritarianism, and the socio-political impact of technology.</p></div></div></div></div>
    <!-- Modal 4 -->
    <div class="modal fade" id="abstractModal4" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>Antimicrobial resistance (AMR) is a significant global health threat, necessitating rapid and accurate prediction from genomic data. This study introduces an explainable, lightweight ensemble model that combines a one-dimensional convolutional neural network (1D CNN) and an XGBoost classifier to predict AMR in Escherichia coli. Our model leverages a novel feature fusion approach, integrating sequence motifs from resistance genes with pan-genomic data, including singleton gene families. The 1D CNN excels at capturing localized patterns within gene sequences, while XGBoost effectively models complex interactions in the broader genomic context. To enhance interpretability, we employ SHapley Additive exPlanations (SHAP), providing insights into the model's decision-making process at both the gene and feature levels. Evaluated on a comprehensive dataset, our ensemble model demonstrates state-of-the-art performance in AMR prediction, outperforming existing methods in accuracy and computational efficiency. The lightweight nature of the model makes it suitable for deployment in resource-constrained settings, offering a promising tool for genomic surveillance and clinical diagnostics.</p></div></div></div></div>
    <!-- Modal 5 -->
    <div class="modal fade" id="abstractModal5" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>This paper introduces AudioFuse, a novel hybrid deep learning architecture for robust phonocardiogram (PCG) classification. Accurate and automated analysis of heart sound signals is crucial for the early detection of cardiovascular diseases. Existing methods often rely on either spectral or temporal features, failing to capture the full complexity of PCG signals. AudioFuse addresses this limitation by integrating a Vision Transformer (ViT) for spectral analysis and a one-dimensional convolutional neural network (1D CNN) for temporal feature extraction. The ViT branch processes Mel-spectrogram images, capturing global contextual information and subtle frequency patterns. Concurrently, the 1D CNN branch operates on the raw waveform, extracting localized time-domain features. A late-fusion mechanism combines the outputs of both branches, creating a unified and comprehensive representation. We evaluate AudioFuse on a publicly available PCG dataset, demonstrating that it achieves state-of-the-art performance in multi-class heart sound classification. The hybrid approach proves particularly effective in noisy environments, highlighting its potential for real-world clinical applications.</p></div></div></div></div>
    <!-- Modal 6 -->
    <div class="modal fade" id="abstractModal6" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>Deep Learning (DL) has shown great potential in various fields, but its performance is often hampered by overfitting, especially when training data is scarce. This paper presents a novel approach called Divide to Conquer (D2C) to mitigate overfitting. In D2C, instead of training a single DL model on the whole dataset, we train multiple simple DL models on different disjoint subsets of the dataset. For inference on an unseen test sample, we use the prediction of the model whose training subset is 'closest' to the test sample. We have conducted extensive experiments on several benchmark datasets (e.g., CIFAR-10, CIFAR-100, Tiny ImageNet) and have shown that D2C outperforms the baseline approach of training a single model in a centralized way. Our results demonstrate that D2C can be an effective strategy to combat overfitting and improve the generalization of DL models.</p></div></div></div></div>
    <!-- Modal 7 -->
    <div class="modal fade" id="abstractModal7" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>Facial Expression Recognition is an important field of study with applications in a wide variety of domains. The application of deep learning-based approaches for facial expression recognition has seen a rising trend in recent years. Training deep neural networks for this task, on the other hand, is a challenging task because it necessitates a huge amount of data as well as a significant amount of computing power. Moreover, sharing data in a centralized server poses some serious privacy concerns. In this paper, we propose FedNet, a federated learning-based approach for facial expression recognition. We have shown that our proposed approach can achieve comparable performance to the traditional centralized approach while preserving the privacy of the user data. Our proposed approach can be used in real-world applications where data privacy is a major concern.</p></div></div></div></div>
    <!-- Modal 8 -->
    <div class="modal fade" id="abstractModal8" tabindex="-1"><div class="modal-dialog modal-lg modal-dialog-centered"><div class="modal-content"><div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><p>This paper proposes a method for classifying the five stages of sleep (W, N1, N2, N3, and R) using bioradiolocation. Bioradiolocation is a technique that uses radio waves to measure physiological parameters such as respiration and heart rate. We have used a publicly available dataset of bioradiolocation signals from 25 healthy subjects. We have extracted time and frequency domain features from the signals and have used a random forest classifier to classify the sleep stages. We have achieved a classification accuracy of 80.2% which is comparable to the state-of-the-art methods. Our proposed method is non-invasive and can be used for long-term monitoring of sleep.</p></div></div></div></div>

    <!-- Footer -->
    <footer class="text-center">
        <div class="container">
            <p>&copy; 2025 Md. Saiful Bari Siddiqui. All rights reserved.</p>
        </div>
    </footer>

    <!-- JS Scripts (Same as index.html) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const fadeElements = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        });
        fadeElements.forEach(element => {
            observer.observe(element);
        });
    </script>
</body>
</html>
